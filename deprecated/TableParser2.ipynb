{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TABLE Parser\n",
    "#Infers a table with arbitrary number of columns from reoccuring patterns in text lines\n",
    "\n",
    "#Main assumptions Table identificatin:\n",
    "#1) each row is either in one line or not a row at all [DONE]\n",
    "#2) each column features at least one number (=dollar amount) [MISSING]\n",
    "#2a) each column features at least one date-like string\n",
    "#3) a table exists if rows are in narrow consecutive order and share similarities --> scoring algo [DONE] \n",
    "#4) each column is separated by more than 2 consecutive whitespace indicators (e.g. '  ' or '..')\n",
    "\n",
    "#Feature List:\n",
    "#1) Acknowledge Footnotes / make lower meta-data available\n",
    "#2) make delimiter length smartly dependent on number of columns (possible iterative approach)\n",
    "#3) expand non canonical values in tables [DONE] .. but not to the extent how types match up  --> use this to further\n",
    "## delineate between caption and headers\n",
    "#4) UI: parameterize extraction on the show page on the fly\n",
    "#5) more type inference (e.g. date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import codecs\n",
    "import string\n",
    "from collections import OrderedDict\n",
    "\n",
    "config = { \"min_delimiter_length\" : 3, \"min_columns\": 2, \"min_consecutive_rows\" : 3, \"max_grace_rows\" : 2,\n",
    "          \"caption_reorder_tolerance\" : 10.0, \"meta_info_lines_above\" : 8, \"aggregate_captions_missing\" : 0.45}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "from flask import Flask, request, redirect, url_for, send_from_directory\n",
    "from werkzeug import secure_filename\n",
    "\n",
    "from flask import jsonify, render_template, make_response\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Regex tester online: https://regex101.com\n",
    "#Contrast with Basic table parsing capabilities of http://docs.astropy.org/en/latest/io/ascii/index.html\n",
    "\n",
    "tokenize_pattern = \"[.]{%i,}|[\\ \\$]{%i,}|\" % ((config['min_delimiter_length'],)*2)\n",
    "tokenize_pattern = \"[.\\ \\$]{%i,}\" % (config['min_delimiter_length'],)\n",
    "\n",
    "column_pattern = OrderedDict()\n",
    "#column_pattern['large_num'] = ur\"\\d{1,3}(,\\d{3})*(\\.\\d+)?\"\n",
    "column_pattern['large_num'] = ur\"(([0-9]{1,3})(,\\d{3})+(\\.[0-9]{2})?)\"\n",
    "column_pattern['small_float'] = ur\"[0-9]+\\.[0-9]+\"\n",
    "column_pattern['integer'] = ur\"^\\s*[0-9]+\\s*$\"\n",
    "#column_pattern['other'] = ur\"([a-zA-Z0-9]{2,}\\w)\"\n",
    "column_pattern['other'] = ur\".+\"\n",
    "\n",
    "subtype_indicator = OrderedDict()\n",
    "subtype_indicator['dollar'] = r\".*\\$.*\"\n",
    "subtype_indicator['rate'] = r\"[%]\"\n",
    "#enter date's here if we want earlier refinement\n",
    "subtype_indicator['year'] = \"(20[0-9]{2})|(19[0-9]{2})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import dateutil.parser as date_parser\n",
    "def tag_token(token, ws):\n",
    "    for t, p in column_pattern.iteritems():\n",
    "        result = re.search(p, token)\n",
    "        if result:\n",
    "            leftover = token[:result.start()] + token[result.end():]\n",
    "            value = token[result.start():result.end()]\n",
    "            \n",
    "            #First match on left-overs\n",
    "            subtype = \"none\"\n",
    "            for sub, indicator in subtype_indicator.iteritems():\n",
    "                if re.match(indicator, leftover): subtype = sub\n",
    "            #Only if no indicator matched there, try on full token\n",
    "            if subtype == \"none\":\n",
    "                for sub, indicator in subtype_indicator.iteritems():\n",
    "                    if re.match(indicator, token): subtype = sub                    \n",
    "            #Only if no indicator matched again, try on whitespace\n",
    "            if subtype == \"none\":\n",
    "                for sub, indicator in subtype_indicator.iteritems():\n",
    "                    if re.match(indicator, ws): subtype = sub\n",
    "            #print token, \":\", ws, \":\", subtype\n",
    "            \n",
    "            return t, subtype, value, leftover\n",
    "    return \"unknown\", \"none\", token, \"\"\n",
    "    \n",
    "def row_feature(line):\n",
    "    features = []\n",
    "    matches = re.finditer(tokenize_pattern, line)\n",
    "    start_end = [ (match.start(), match.end()) for match in matches]\n",
    "    if len(start_end) < 1: \n",
    "        return features\n",
    "    \n",
    "    tokens = re.split(tokenize_pattern, line)\n",
    "    if tokens[0] == \"\": \n",
    "        tokens = tokens[1:]\n",
    "    else:\n",
    "        start_end = [(0,0)] + start_end\n",
    "    \n",
    "    for se, token in zip(start_end, tokens):\n",
    "        t, subtype, value, _ = tag_token(token, line[se[0]:se[1]])\n",
    "        feature = {\"start\" : se[1], \"value\" : value, \"type\" : t, \"subtype\" : subtype}\n",
    "        features.append(feature)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Establish whether amount of rows is above a certain threshold and whether there is at least one number\n",
    "def row_qualifies(row):\n",
    "    return len(row) >= config['min_columns'] and sum( 1 if c['type'] in ['large_num', 'small_float', 'integer'] else 0 for c in row) > 0\n",
    "\n",
    "def row_equal_types(row1, row2):\n",
    "    same_types = sum (map(lambda t: 1 if t[0]==t[1] else 0, ((c1['type'], c2['type']) for c1, c2 in zip(row1, row2))))\n",
    "    return same_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_row_spans(row_features, row_qualifies):    \n",
    "\n",
    "    min_consecutive = config[\"min_consecutive_rows\"]\n",
    "    grace_rows = config['max_grace_rows']\n",
    "\n",
    "    last_qualified = None    \n",
    "    consecutive = 0\n",
    "    underqualified = 0\n",
    "    i = 0\n",
    "    \n",
    "    for row in row_features:\n",
    "        if row_qualifies(row):\n",
    "            underqualified = 0\n",
    "            if last_qualified is None:\n",
    "                last_qualified = i\n",
    "                consecutive = 1\n",
    "            else:\n",
    "                consecutive += 1    \n",
    "        else:\n",
    "            underqualified += 1\n",
    "            if underqualified > grace_rows:\n",
    "                if consecutive >= min_consecutive:\n",
    "                    yield last_qualified, i-underqualified+1\n",
    "                    last_qualified = None                \n",
    "                    consecutive = 0\n",
    "                else:\n",
    "                    last_qualified = None\n",
    "                    consecutive = 0\n",
    "                underqualified = 0\n",
    "        #print i, underqualified, last_qualified, consecutive#, \"\" or row\n",
    "        i += 1\n",
    "        \n",
    "    if consecutive >= min_consecutive:\n",
    "        yield last_qualified, i-underqualified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def readjust_cols(feature_row, slots):\n",
    "        feature_new = [{'value' : 'NaN'}] * len(slots)\n",
    "        for v in feature_row:\n",
    "            dist = [ abs((float(v['start'])) - s) for s in slots ]\n",
    "            val , idx = min((val, idx) for (idx, val) in enumerate(dist))\n",
    "            if val <= config['caption_reorder_tolerance']: feature_new[idx] = v\n",
    "        return feature_new\n",
    "\n",
    "def normalize_rows(rows_in, structure):\n",
    "    \n",
    "    slots = [c['start'] for c in structure] \n",
    "    nrcols = len(structure)\n",
    "    \n",
    "    for r in rows_in:\n",
    "        if len(r) != nrcols:\n",
    "            if len(r)/float(nrcols) > config['aggregate_captions_missing']:          \n",
    "                yield readjust_cols(r, slots)\n",
    "        else:\n",
    "            yield r\n",
    "\n",
    "#TODO: make side-effect free\n",
    "def structure_rows(row_features, meta_features):\n",
    "    #Determine maximum nr. of columns\n",
    "    lengths = [len(r) for r in row_features]\n",
    "    nrcols = max(lengths)\n",
    "    canonical = filter(lambda r: len(r) == nrcols , row_features)\n",
    "    \n",
    "    #print canonical\n",
    "    \n",
    "    structure = []\n",
    "    values = []\n",
    "    for i in range(nrcols):\n",
    "        col = {}\n",
    "        col['start'] = float (sum (c[i]['start'] for c in canonical )) / len(canonical)\n",
    "    \n",
    "        types = Counter(c[i]['type'] for c in canonical)\n",
    "        col['type'] = types.most_common(1)[0][0]\n",
    "        subtypes = Counter(c[i]['subtype'] for c in canonical if c[i]['subtype'] is not \"none\")        \n",
    "        subtype = \"none\" if len(subtypes) == 0 else subtypes.most_common(1)[0][0]\n",
    "        col['subtype'] = subtype\n",
    "        structure.append(col)\n",
    "    \n",
    "    #Add the first non canonical rows to the meta_features above data\n",
    "    for r in row_features:\n",
    "        if r in canonical:\n",
    "            break\n",
    "        else:\n",
    "            meta_features.append(r)\n",
    "            row_features.remove(r)\n",
    "     \n",
    "    #Try to find caption from first rows above the data, skip one empty row if necessary\n",
    "    #Todo: make two steps process cleaner and more general --> use type similarity\n",
    "    if len(meta_features[-1]) == 0: meta_features = meta_features[:-1]\n",
    "    caption = meta_features[-1] if len(meta_features[-1])/float(nrcols) > config['aggregate_captions_missing'] else None \n",
    "    if caption:\n",
    "        slots = [c['start'] for c in structure] \n",
    "        meta_features = meta_features[:-1]              \n",
    "        if len(caption) != nrcols: caption = readjust_cols(caption, slots)\n",
    "        if len(meta_features[-1])/float(nrcols) > config['aggregate_captions_missing']:\n",
    "            caption2 = readjust_cols(meta_features[-1], slots)\n",
    "            for c,c2 in zip(caption, caption2):\n",
    "                if c2['value'] != 'NaN':\n",
    "                    c['value'] = c2['value'] + ' ' + c['value']\n",
    "            meta_features = meta_features[:-1]\n",
    "      \n",
    "        #Assign captions as the value in structure\n",
    "        for i, c in enumerate(caption):\n",
    "            structure[i]['value'] = c['value']\n",
    "    \n",
    "    headers = []\n",
    "    for h in meta_features:\n",
    "        if len(h) == 1:\n",
    "            headers.append(h[0]['value'])   \n",
    "    \n",
    "    #Expand all the non canonical rows with NaN values (Todo: if types are very similar)\n",
    "    normalized_data = [r for r in normalize_rows(row_features, structure)]            \n",
    "    \n",
    "    return structure, normalized_data, headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def output_table_html(txt_path):\n",
    "    out = []\n",
    "    out.append(\"--------\" + txt_path + \"--------\")\n",
    "\n",
    "    with codecs.open(txt_path, \"r\", \"utf-8\") as f:\n",
    "\n",
    "        lines = [l.encode('ascii', 'ignore').replace('\\n', '').replace('\\r','') for l in f]\n",
    "        rows = [row_feature(l) for l in lines]\n",
    "\n",
    "        for b,e in filter_row_spans(rows, row_qualifies):\n",
    "            out.append(\"TABLE STARTING FROM LINE %i to %i\" % (b,e))\n",
    "            table = rows[b:e]\n",
    "            structure, data, headers = structure_rows(table, rows[b-config['meta_info_lines_above']:b])\n",
    "\n",
    "            for h in headers: out.append(h)\n",
    "            if caption: \n",
    "                out.append(\"\\t\".join(caption))\n",
    "            else:\n",
    "                out.append('NO COLUMN NAMES DETECTED')\n",
    "\n",
    "            for f in rows[b:e]:\n",
    "                cols = \"\\t|\\t\".join([col['value']+\" (%s, %s)\" % (col['type'], col['subtype']) for col in f])\n",
    "                out.append(\"%i %s\" % (len(f), cols) )\n",
    "    return out\n",
    "\n",
    "def return_table(rows):\n",
    "    for b,e in filter_row_spans(rows, row_qualifies):\n",
    "        table = {'begin_line' : b, 'end_line' : e}\n",
    "\n",
    "        data_rows = rows[b:e]\n",
    "        meta_rows = rows[b-config['meta_info_lines_above']:b]\n",
    "\n",
    "        structure, data, headers = structure_rows(data_rows, meta_rows)\n",
    "\n",
    "        #Construct df\n",
    "        captions = [(col['value'] if 'value' in col.keys() else \"---\") +\"\\n(%s, %s)\" % (col['type'], col['subtype']) for col in structure]\n",
    "\n",
    "        table['captions'] = captions\n",
    "        table['data'] = data           \n",
    "        table['header'] = \" | \".join(headers)\n",
    "\n",
    "        return table \n",
    "\n",
    "def return_tables(txt_path):\n",
    "    \n",
    "    #Uniquely identify tables by their first row\n",
    "    tables = OrderedDict()\n",
    "    \n",
    "    with codecs.open(txt_path, \"r\", \"utf-8\") as f:\n",
    "        lines = [l.replace('\\n', '').replace('\\r', '') for l in f]\n",
    "        rows = [row_feature(l) for l in lines] \n",
    "        \n",
    "        for b,e in filter_row_spans(rows, row_qualifies):\n",
    "            table = {'begin_line' : b, 'end_line' : e}\n",
    "            \n",
    "            data_rows = rows[b:e]\n",
    "            meta_rows = rows[b-config['meta_info_lines_above']:b]\n",
    "            \n",
    "            structure, data, headers = structure_rows(data_rows, meta_rows)\n",
    "            \n",
    "            #Construct df\n",
    "            captions = [(col['value'] if 'value' in col.keys() else \"---\") +\"\\n(%s, %s)\" % (col['type'], col['subtype']) for col in structure]\n",
    "            \n",
    "            table['captions'] = captions\n",
    "            table['data'] = data           \n",
    "            table['header'] = \" | \".join(headers)\n",
    "            \n",
    "            tables[b] = table\n",
    "    \n",
    "    return tables\n",
    "\n",
    "def table_to_df(table):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for i, c in enumerate(table['captions']):\n",
    "        values = []\n",
    "        for r in table['data']:\n",
    "            values.append(r[i]['value'])\n",
    "        df[c] = values\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web App ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TITLE = \"docX - Table View\"\n",
    "\n",
    "scripts = [\n",
    "    \"./bower_components/jquery/dist/jquery.min.js\",\n",
    "    \"./bower_components/datatables/media/js/jquery.dataTables.js\",\n",
    "    \"./bower_components/d3/d3.min.js\",\n",
    "    \"./bower_components/metrics-graphics/dist/metricsgraphics.js\",\n",
    "    \"./require.min.js\",\n",
    "    \"./bower_components/react/react.js\",\n",
    "    \"./bower_components/react-bootstrap/react-bootstrap.min.js\",\n",
    "    \"./bower_components/pyxley/build/pyxley.js\",\n",
    "]\n",
    "\n",
    "css = [\n",
    "    \"./bower_components/bootstrap/dist/css/bootstrap.min.css\",\n",
    "    \"./bower_components/metrics-graphics/dist/metricsgraphics.css\",\n",
    "    \"./bower_components/datatables/media/css/jquery.dataTables.min.css\",\n",
    "    \"./css/main.css\",\n",
    "    \"./css/style.css\"\n",
    "]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "UPLOAD_FOLDER = './'\n",
    "ALLOWED_EXTENSIONS = set(['txt', 'pdf'])\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "\n",
    "def get_extension(filename):\n",
    "    return '.' in filename and \\\n",
    "           filename.rsplit('.', 1)[1] \n",
    "\n",
    "def allowed_file(filename):\n",
    "    return get_extension(filename) in ALLOWED_EXTENSIONS\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def upload_file():\n",
    "    if request.method == 'POST':\n",
    "        file = request.files['file']\n",
    "        min_columns = request.form['min_columns']\n",
    "        if file and allowed_file(file.filename):\n",
    "            filename = secure_filename(file.filename)\n",
    "            extension = get_extension(file.filename)\n",
    "            file.save(os.path.join(app.config['UPLOAD_FOLDER'], extension, filename))\n",
    "            return redirect(url_for('uploaded_file',\n",
    "                                    filename=filename, min_columns=min_columns))\n",
    "\n",
    "    return render_template('index.html',\n",
    "        title=TITLE ,\n",
    "        css=css)\n",
    "\n",
    "@app.route('/show/<filename>')\n",
    "def uploaded_file(filename):\n",
    "    extension = get_extension(filename)\n",
    "    path = os.path.join(app.config['UPLOAD_FOLDER'], extension, filename)\n",
    "    txt_path = os.path.join(app.config['UPLOAD_FOLDER'], 'txt', filename)\n",
    "    if extension == \"pdf\":\n",
    "        txt_path += '.txt'\n",
    "        if not os.path.isfile(txt_path):\n",
    "        #Layout preservation crucial to preserve clues about tabular data\n",
    "            cmd = \"pdftotext -layout %s %s\" % (path, txt_path)\n",
    "            os.system(cmd)\n",
    "            \n",
    "    min_columns = request.args.get('min_columns')\n",
    "    tables = return_tables(txt_path)\n",
    "\n",
    "    #Construct histogram\n",
    "    lines_per_page = 80\n",
    "    nr_data_rows = []\n",
    "    for b, t in tables.iteritems():\n",
    "        e = t['end_line']\n",
    "        #print b, e\n",
    "        for l in range(b, e):\n",
    "            page = l / lines_per_page\n",
    "            if len(nr_data_rows) <= page:\n",
    "                nr_data_rows += ([0]*(page-len(nr_data_rows)+1))\n",
    "            nr_data_rows[page] += 1\n",
    "    dr = pd.DataFrame()\n",
    "    dr['value'] = nr_data_rows\n",
    "    dr['page'] = range(0, len(dr))\n",
    "    \n",
    "    #plot the row density\n",
    "    chart = filename+\".jpg\"\n",
    "    fig, ax = plt.subplots( nrows=1, ncols=1, figsize=(10,5) )  # create figure & 1 axis\n",
    "    ax.set_xlabel('page nr.')\n",
    "    ax.set_ylabel('number of data rows')\n",
    "    ax.set_title('Distribution of Rows with Data')\n",
    "    ax.plot(dr['page'], dr['value'], )\n",
    "    fig.savefig('./static/ug/'+chart)   # save the figure to file\n",
    "    plt.close(fig)    # close the figure\n",
    "\n",
    "    notices = ['Extraction Results for ' + filename, 'Ordered by lines']    \n",
    "    dfs = (table_to_df(table).to_html() for table in tables.values())\n",
    "    headers = []\n",
    "    for t in tables.values():\n",
    "        if 'header' in t:\n",
    "            headers.append(t['header'])\n",
    "        else:\n",
    "            headers.append('-')\n",
    "    meta_data = [{'begin_line' : t['begin_line'], 'end_line' : t['end_line']} for t in tables.values()]\n",
    "\n",
    "    return render_template('viewer.html',\n",
    "        title=TITLE + ' - ' + filename,\n",
    "        base_scripts=scripts, filename=filename,\n",
    "        css=css, notices = notices, tables = dfs, headers=headers, meta_data=meta_data, chart='../static/ug/'+chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@app.route('/inspector/<filename>')\n",
    "def inspector(filename):\n",
    "    extension = 'txt'\n",
    "    path = os.path.join(app.config['UPLOAD_FOLDER'], extension, filename)\n",
    "    begin_line = int(request.args.get('data_begin'))\n",
    "    end_line = int(request.args.get('data_end'))\n",
    "    margin_top = config[\"meta_info_lines_above\"]\n",
    "    margin_bottom = margin_top\n",
    "    \n",
    "    notices = ['original view into ' + filename + 'for table @'+str(begin_line)]\n",
    "    with open(path) as file:\n",
    "        lines = [l.decode('ascii', 'ignore') for l in file][begin_line - margin_top:end_line + margin_bottom]\n",
    "        top_lines = lines[:margin_top]\n",
    "        table_lines = lines[margin_top:margin_top+begin_line-end_line]\n",
    "        bottom_lines = lines[margin_top+begin_line-end_line:]\n",
    "    \n",
    "    offset = begin_line-margin_top\n",
    "    table_id = begin_line\n",
    "    \n",
    "    return render_template('inspector.html',\n",
    "        title=TITLE,\n",
    "        base_scripts=scripts, css=css, notices = notices, top_lines=top_lines, filename=filename,\n",
    "        table_lines=table_lines, bottom_lines=bottom_lines, offset=offset, table_id=begin_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#app.run(host='0.0.0.0')\n",
    "app.run(debug=True, host='0.0.0.0', port = 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tests ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for file in os.listdir('txt'):\n",
    "    \n",
    "    print (\"--------\" + file + \"--------\")\n",
    "    tables = return_tables('txt/'+file)\n",
    "    \n",
    "    #print tables\n",
    "    \n",
    "    #Construct histogram\n",
    "    lines_per_page = 80\n",
    "    nr_data_rows = []\n",
    "    for b, t in tables.iteritems():\n",
    "        e = t['end_line']\n",
    "        #print b, e\n",
    "        for l in range(b, e):\n",
    "            page = l / lines_per_page\n",
    "            if len(nr_data_rows) <= page:\n",
    "                nr_data_rows += ([0]*(page-len(nr_data_rows)+1))\n",
    "            nr_data_rows[page] += 1\n",
    "    dr = pd.DataFrame()\n",
    "    dr['value'] = nr_data_rows\n",
    "    dr['page'] = range(0, len(dr))    \n",
    "    #print dr.head()\n",
    "\n",
    "    line_nrs = [('line %i-%i' % (t['begin_line'], t['end_line'])) for t in tables.values() ]\n",
    "    print line_nrs\n",
    "    \n",
    "    for k, table in tables.iteritems():\n",
    "        df = table_to_df(table)\n",
    "        #print k, ' !!! ', table['header'], ' -----------------'\n",
    "        print df.head()\n",
    "\n",
    "\n",
    "    #print dr"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Make a Button\n",
    "cols = [c for c in df.columns if c != \"Date\"]\n",
    "btn = SelectButton(\"Data\", cols, \"Data\", \"Steps\")\n",
    "\n",
    "# Make a FilterFrame and add the button to the UI\n",
    "ui.add_filter(btn)\n",
    "\n",
    "# Now make a FilterFrame for the histogram\n",
    "hFig = Figure(\"/mghist/\", \"myhist\")\n",
    "hFig.layout.set_size(width=450, height=200)\n",
    "hFig.layout.set_margin(left=40, right=40)\n",
    "hFig.graphics.animate_on_load()\n",
    "# Make a histogram with 20 bins\n",
    "hc = Histogram(sf, hFig, \"value\", 20, init_params={\"Data\": \"Steps\"})\n",
    "ui.add_chart(hc)\n",
    "\n",
    "# Let's play with our input\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df[\"week\"] = df[\"Date\"].apply(lambda x: x.isocalendar()[1])\n",
    "gf = df.groupby(\"week\").agg({\n",
    "        \"Date\": [np.min, np.max],\n",
    "        \"Steps\": np.sum,\n",
    "        \"Calories Burned\": np.sum,\n",
    "        \"Distance\": np.sum\n",
    "    }).reset_index()\n",
    "f = lambda x: '_'.join(x) if (len(x[1]) > 0) and x[1] != 'sum' else x[0]\n",
    "gf.columns = [f(c) for c in gf.columns]\n",
    "gf = gf.sort_index(by=\"week\", ascending=False)\n",
    "gf[\"Date_amin\"] = gf[\"Date_amin\"].apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
    "gf[\"Date_amax\"] = gf[\"Date_amax\"].apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "cols = OrderedDict([\n",
    "    (\"week\", {\"label\": \"Week\"}),\n",
    "    (\"Date_amin\", {\"label\": \"Start Date\"}),\n",
    "    (\"Date_amax\", {\"label\": \"End Date\"}),\n",
    "    (\"Calories Burned\", {\"label\": \"Calories Burned\"}),\n",
    "    (\"Steps\", {\"label\": \"Steps\"}),\n",
    "    (\"Distance\", {\"label\": \"Distance (mi)\", \"format\": \"%5.2f\"})\n",
    "])\n",
    "\n",
    "tb = DataTable(\"mytable\", \"/mytable/\", gf, columns=cols, paging=True, pageLength=5)\n",
    "ui.add_chart(tb)\n",
    "\n",
    "sb = ui.render_layout(app, \"./static/layout.js\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_string =\"\"\"\n",
    "        The following table sets forth statistical information relating to the Water System during the five\n",
    "Fiscal Years shown.\n",
    "                                                 TABLE 1\n",
    "                                   WATER SYSTEM STATISTICS\n",
    "                                                                               Fiscal Year Ended June 30\n",
    "                                                                  2014         2013       2012     2011      2010\n",
    "Anaheim Population Served ..................................     348,305      346,161   343,793   341,034   336,265\n",
    "Population Served Outside City (Est.) ...................          8,457        9,000     9,000     9,000     9,000\n",
    "        Total Population Served ...........................      356,762      355,161   352,793   350,034   345,265\n",
    "\n",
    "  Total Water Sales (Million Gallons) ...................         20,740       20,465    19,672    19,526    20,488\n",
    "\n",
    "Capacity (Million Gallons Per Day)\n",
    "  From MWD Connections ...................................             110       110       110       110       110\n",
    "  From Water System Wells (Average) ...............                     79        86        88        81        75\n",
    "        Total Supply Capacity .............................            189       196       198       191       185\n",
    "\n",
    "   Treatment Plant Capacity ..................................          15        15        15        15        15\n",
    "\n",
    "Peak Day Distribution (Million Gallons) ...............                82.2      78.7     79.2      87.2      87.2\n",
    "Average Daily Distribution (Million Gallons) .......                   60.3      58.9     57.3      59.4      56.1\n",
    "Average Daily Sales Per Capita (Gallons) .............                159.3     157.9    152.8     152.8     162.6\n",
    "__________________\n",
    "Source: Anaheim\n",
    "\n",
    "Existing Facilities\n",
    "\n",
    "\"\"\".decode('ascii', 'ignore').split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_string =\"\"\"\n",
    "                         CALIFORNIA MUNICIPAL FINANCE AUTHORITY\n",
    "                                   Revenue Bonds, Series 2015-A\n",
    "                              (City of Anaheim Water System Project)\n",
    "\n",
    "                                          MATURITY SCHEDULE\n",
    "\n",
    "                                            $58,205,000 Serial Bonds\n",
    "\n",
    "  Maturity Date              Principal                Interest\n",
    "   (October 1)               Amount                     Rate                   Yield                  CUSIP†\n",
    "       2015                 $ 775,000                 2.000%                   0.100%             13048TTV5\n",
    "       2016                  1,575,000                2.000                    0.300              13048TTW3\n",
    "       2017                  1,620,000                3.000                    0.660              13048TTX1\n",
    "       2018                  1,675,000                4.000                    0.930              13048TTY9\n",
    "       2019                  2,045,000                5.000                    1.150              13048TTZ6\n",
    "       2020                  2,155,000                5.000                    1.320              13048TUA9\n",
    "       2021                  2,250,000                4.000                    1.520              13048TUB7\n",
    "       2022                  2,610,000                5.000                    1.670              13048TUC5\n",
    "       2023                  2,730,000                4.000                    1.810              13048TUD3\n",
    "       2024                  2,875,000                5.000                    1.920              13048TUE1\n",
    "       2025                  3,025,000                5.000                    2.030(c)           13048TUF8\n",
    "       2026                  3,190,000                5.000                    2.200(c)           13048TUG6\n",
    "       2027                  3,355,000                5.000                    2.320(c)           13048TUH4\n",
    "       2028                  3,520,000                5.000                    2.450(c)           13048TUJ0\n",
    "       2029                  3,700,000                5.000                    2.520(c)           13048TUK7\n",
    "       2030                  3,880,000                5.000                    2.600(c)           13048TUL5\n",
    "       2031                  4,055,000                4.000                    3.140(c)           13048TUM3\n",
    "       2032                  4,220,000                4.000                    3.190(c)           13048TUN1\n",
    "       2033                  4,390,000                4.000                    3.230(c)           13048TUP6\n",
    "       2034                  4,560,000                4.000                    3.270(c)           13048TUQ4\n",
    "\n",
    "     $24,535,000 4.000% Term Bonds due October 1, 2040 – Yield: 3.400%(c); CUSIP†: 13048TUR2\n",
    "     $13,145,000 5.250% Term Bonds due October 1, 2045 – Yield: 2.970%(c); CUSIP†: 13048TUS0\n",
    "          \n",
    "\"\"\".decode('ascii', 'ignore').split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_string = \"\"\"\n",
    "\n",
    "\f",
    "                                       SCHEDULED DEBT SERVICE\n",
    "        The scheduled debt service for the Bonds is as follows, assuming no optional redemptions prior to maturity:\n",
    "                               FORESTVILLE UNION SCHOOL DISTRICT\n",
    "                            General Obligation Bonds (Election of 2010, Series 2012)\n",
    "                                     Semi-Annual Debt Service Payments\n",
    "\n",
    "                                                             Compounded         Total Periodic    Total Annual Debt\n",
    "Period Ending        Principal            Interest             Interest         Debt Service            Service\n",
    " Feb. 1, 2013                –              $57,033.85                 –             $57,033.85                –\n",
    " Aug. 1, 2013                –               37,331.25                 –              37,331.25          $94,365.10\n",
    " Feb. 1, 2014                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2014                –               37,331.25                 –              37,331.25           74,662.50\n",
    " Feb. 1, 2015                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2015                –               37,331.25                 –              37,331.25           74,662.50\n",
    " Feb. 1, 2016                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2016                –               37,331.25                 –              37,331.25           74,662.50\n",
    " Feb. 1, 2017                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2017                –               37,331.25                 –              37,331.25           74,662.50\n",
    " Feb. 1, 2018                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2018                –               37,331.25                 –              37,331.25           74,662.50\n",
    " Feb. 1, 2019                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2019                –               37,331.25                 –              37,331.25           74,662.50\n",
    " Feb. 1, 2020                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2020           $5,725.80            37,331.25            $9,274.20           52,331.25           89,662.50\n",
    " Feb. 1, 2021                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2021            5,095.95            37,331.25             9,904.05           52,331.25           89,662.50\n",
    " Feb. 1, 2022                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2022            6,047.20            37,331.25            13,952.80           57,331.25           94,662.50\n",
    " Feb. 1, 2023                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2023            6,727.50            37,331.25            18,272.50           62,331.25           99,662.50\n",
    " Feb. 1, 2024                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2024            7,184.70            37,331.25            22,815.30           67,331.25          104,662.50\n",
    " Feb. 1, 2025                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2025            7,460.25            37,331.25            27,539.75           72,331.25          109,662.50\n",
    " Feb. 1, 2026                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2026            6,639.50            37,331.25            28,360.50           72,331.25          109,662.50\n",
    " Feb. 1, 2027                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2027            7,597.35            37,331.25            37,402.65           82,331.25          119,662.50\n",
    " Feb. 1, 2028                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2028            6,761.70            37,331.25            38,238.30           82,331.25          119,662.50\n",
    " Feb. 1, 2029                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2029            6,686.50            37,331.25            43,313.50           87,331.25          124,662.50\n",
    " Feb. 1, 2030                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2030            6,546.10            37,331.25            48,453.90           92,331.25          129,662.50\n",
    " Feb. 1, 2031                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2031            6,885.45            37,331.25            58,114.55          102,331.25          139,662.50\n",
    " Feb. 1, 2032                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2032            6,598.90            37,331.25            63,401.10          107,331.25          144,662.50\n",
    " Feb. 1, 2033                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2033            6,292.50            37,331.25            68,707.50          112,331.25          149,662.50\n",
    " Feb. 1, 2034                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2034            6,346.95            37,331.25            78,653.05          122,331.25          159,662.50\n",
    " Feb. 1, 2035                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2035            5,649.10            37,331.25            79,350.90          122,331.25          159,662.50\n",
    " Feb. 1, 2036                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2036            5,619.25            37,331.25            89,380.75          132,331.25          169,662.50\n",
    " Feb. 1, 2037                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2037           44,881.20            37,331.25           375,118.80          457,331.25          494,662.50\n",
    " Feb. 1, 2038                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2038           92,550.60            37,331.25           342,449.40          472,331.25          509,662.50\n",
    " Feb. 1, 2039                –               37,331.25                 –              37,331.25                –\n",
    " Aug. 1, 2039          287,012.60            37,331.25           167,987.40          492,331.25          529,662.50\n",
    " Feb. 1, 2040                –               32,278.13                 –              32,278.13                –\n",
    " Aug. 1, 2040          480,000.00            32,278.13                 –             512,278.13          544,556.26\n",
    " Feb. 1, 2041                –               22,378.13                 –              22,378.13                –\n",
    " Aug. 1, 2041          520,000.00            22,378.13                 –             542,378.13          564,756.26\n",
    " Feb. 1, 2042                –               11,653.13                 –              11,653.13                –\n",
    " Aug. 1, 2042          565,000.00            11,653.13                 –             576,653.13          588,306.26\n",
    " TOTAL               2,099,309.10        $2,168,208.88        $1,620,690.90       $5,888,208.88       $5,888,208.88\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\".split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rows = [row_feature(l) for l in test_string]\n",
    "\n",
    "table = return_table(rows)\n",
    "df = table_to_df(table)\n",
    "\n",
    "print df.columns\n",
    "print df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in os.listdir('txt'):\n",
    "    \n",
    "    print (\"--------\" + file + \"--------\")\n",
    "    \n",
    "    with codecs.open('txt/'+file, \"r\", \"utf-8\") as f:\n",
    "        \n",
    "        lines = [l.encode('ascii', 'ignore').replace('\\n', '') for l in f]\n",
    "        rows = [row_feature(l) for l in lines]\n",
    "\n",
    "        for b,e in filter_row_spans(rows, row_qualifies):\n",
    "            print \"TABLE STARTING AT LINE\", b\n",
    "            table = rows[b:e]\n",
    "            structure, data, headers = structure_rows(table, rows[b-config['meta_info_lines_above']:b])\n",
    "            print headers\n",
    "            captions = [(col['value'] if 'value' in col.keys() else \"---\") +\" (%s, %s)\" % (col['type'], col['subtype']) for col in structure]\n",
    "            print captions  \n",
    "            for r in data:\n",
    "                cols = [col['value']+\" (%s, %s)\" % (col['type'], col['subtype']) for col in r]\n",
    "                print len(cols), cols\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rstr =\"\"\"\n",
    "Population Served Outside City (Est.) ...................          8,457        9,000     9,000     9,000     9,000\n",
    "        Total Population Served ...........................      356,762      355,161   352,793   350,034   345,265\n",
    "\"\"\".decode('ascii', 'ignore').split(\"\\n\")\n",
    "for r in rstr:\n",
    "    print \"split\", re.split(tokenize_pattern, r)\n",
    "    print \"token\", [v['value'] for v in row_feature(r)], row_feature(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#subtype_indicator['test'] = r'.*\\$.*'\n",
    "for sub, indicator in subtype_indicator.iteritems():\n",
    "    print sub, indicator, re.match(indicator, \"  ..........................................................     $  \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
